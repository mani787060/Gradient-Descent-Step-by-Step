# Gradient Descent Step by Step

-> This project provides a clear, step-by-step breakdown of **Gradient Descent**, explaining how parameters are updated at every iteration.  
-> It includes manual calculations, update formulas, and visualization of how the loss decreases over time.

## Contents:-
-> Gradient Descent explained mathematically
-> Step-by-step parameter updates (m & b)
-> Implementation using NumPy
-> Loss value calculation across iterations
-> Visualization of convergence

## Key Concepts:-
-> Cost function and gradients
-> Learning rate importance
-> Convergence behavior and stopping criteria

## Libraries Used:-
-> NumPy  
-> Pandas  
-> Matplotlib
